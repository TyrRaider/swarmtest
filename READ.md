ИНИЦИАЛИЗАЦИЯ


docker swarm init --advertise-addr 10.11.10.1

docker swarm join --token SWMTKN-1-<token> 10.11.10.1:2377 (токены для менеджеров и воркеров отдельно)

docker swarm join-token (worker|manager)
(токены для менеджеров и воркеров отдельно)

docker node ls 

docker swarm leave

docker node promote node-3

docker node inspect node-4 --pretty

docker node update --availability=pause node-4

После ребута кластер автоматически пересобирается

Статусы нод:
- Active  - готов к выполнению
- Paused - завершает выполнение текущих тасок и не принимает новые
- Drained - передаёт выполнение текущих тасок другим нодам и не принимает новые

------------------------------------------------------------------------------------------------------------------------

SWARM MANAGER


1) API - принимает команду и создает объект service (некоторая агрегация задач)
2) Orchestrator - создает объект task для сервисов (очередь задач)
3) Allocater - Выделяет IP адрес для исполнения задачи
4) Dispatcher - привязывает задачу к ноде
5) Scheduler - даёт задачу worker запустить задачу 

SWARM WORKER

1) Проверяет есть ли для него задачи, если да, то передаёт далее экзекутору
2) Executor - выполняет задачу
3) Выдаёт обратно статус

------------------------------------------------------------------------------------------------------------------------

СЕРВИСЫ

docker service create --name redis redis:latest
docker service ls

2 мода запуска сервисов:
- replicated - указываем необходимое количество реплик сервиса
- global - когда хотим, чтобы на всех нодах запустился сервис
--mode (replicated, global, replicated-job, global-job)
--replicas 5 

docker service inspect redis --pretty

docker service ps redis - просмотр тасок сервиса и где они выполняются

docker service logs redis - просмотр логов сервиса, логи централизованы и можно посмотреть на любом менеджере

docker service remove redis

docker service rollback - можем откатиться до предыдущей версии сервиса (если мы его обновляли через update)

docker service scale redis=2 - масштабируем до 2ух реплик

docker должны быть сохранен service update redis --image=redis:3.0.2 - обновление параметров сервиса

------------------------------------------------------------------------------------------------------------------------

СЕКРЕТЫ И КОНФИГИ

SWARM MANAGER(my_config, my_secret) -> |--config & --secret| -> контейнер(/run/secrets/my_secret, /my_config) 

Внутри контейнера секреты лежат в открытом виде

docker secret ls

docker secret create my_pass sec.txt

docker service create --secret my_pass --name redis redis:latest

docker secret inspect my_pass

docker secret rm my_pass - удаление произведется только после удаления сервиса

echo "6789" | docker config create my_conf -

docker config ls

docker service create --config env_config  --name redis redis:latest

------------------------------------------------------------------------------------------------------------------------

STATEFULL СЕРВИСЫ

Если попытаться запустить сервисы из файла компоуза на сварме, то указанные билды должны уже выполнены, 
а image'ы находится в registry, откуда они будут пулиться на сварм.

Registry является примером statefull-сервиса, где помимо того, что сервис выполняет задачи и работу, у этого
сервиса есть некоторое состояние, которое сохраняется при перезапуске, тоесть если сервис Regsitry перезапущен,
то image'ы должны быть сохранены. В качестве statefull так же можно принять любые DB - Mongo, Postgres и 
очереди сообщений.

Варианты реализации:

1) Shared Mount. 
Например есть 3 ноды, которые смотрят все на один shared mount, это может быть общая подключенная
папка, может быть облачное хранилище (кастомные драйвера). Сервис где угодно может подняться и все реплики
будут смотреть на какую-то одну точку в файловой системе.

2) Constraint. 
Когда мы поднимаем сервис, мы можем ему задать какое-то ограничение, где ему подняться.
Если есть нода, которая соответствует этим ограничениям - он поднимется на ней, если есть несколько нод - он
рандомно выберет ноду и поднимется на ней. Если нет ни одной ноды - сервис будет висеть в состоянии поиска варианта
ноды и не будет запущен.

При помощи docker node update мы можем задавать нодам label, в рамках этих меток мы можем задавать произвольные
ключ и значение, например database: true и можно задавать роли (role: db).

docker node update node-2 --label-add db=true

docker node ls --filter node.label=db - поиск по лейблу

docker service create --name db \
--publish 5000:5000 \
--constraint node.labels.db==true \
--mount type=bind,source=/db,destination=/var/db \
-e DB_HTTP_ADDR=0.0.0.0:5000 mongodb:latest

Благодаря тому, что все сварм ноды находятся в одной сети, 
поэтому когда мы будем обращаться localhost:5000 с любой ноды мы будем попадать на сеть Ingress,
которая нас будет редиректить уже на ноду, где есть этот 5000 порт. 
! Директорию для проброса на нодах необходимо создать заранее! Она не создаётся автоматически. !

------------------------------------------------------------------------------------------------------------------------

OVERLAY NETWORK

Некая виртуальная сеть, которая управляется свармом и соединяет все ноды в кластере.
overlay network --attachable - позволяет стендалон контейнерам присоединяться к сети сервисов.
overlay network --opt encrypted - включение шифрования между контейнерами, влияет на производительность сети.

Дефолтная Ingress-сеть.
Когда мы прокидываем порт из контейнера наружу, то он попадает в Ingress-сеть, которая уже позволяет взаимодействовать
с внешним миром. По сути это встроенный балансировщик, он смотрит все контейнеры, где прокинут порт и по одному начинает 
отправлять на них запросы. Это позволяет балансировать нагрузку.


docker service create --publish 3000:3000 --name ip --replicas=3  localhost:5000/ip:latest 

------------------------------------------------------------------------------------------------------------------------

DOCKER STACK

Обхединение нескольких сервисов. В целом это тот же компоуз.

docker stack ls
docker stack ps
docker stack deploy -c service-stack.yml my_app
docker stack services my_app - состояние и количество реплик контейнеров стэка
docker stack ps my_app - показывает ноды, где выполняются таски стэка


------------------------------------------------------------------------------------------------------------------------

Healthcheck

Механизм проверки состояния контейнера.
Описывается внутри Dockerfile или компоуз файле.
Если хелсчек нагружает контейнер, лучше ставить интервал больше.
Интервал - как часто опрашиваем контейнер, таймаут - время ответа, старт-период - время старта опрашивания,
ретрай - число попыток, после которых выдаётся код ошибки.

HEALTHCHECK --interval=5s --timeout=3s --start-period=5s --retries=2 \
	CMD curl -f http://localhost:3000 || exit 1
(комманда проверки)					(код выхода с ошибкой)

В данном случае, если произойдёт повисание или краш приложения, сварм автоматически перезапустит сервис.


------------------------------------------------------------------------------------------------------------------------

ОТКАЗОУСТОЙЧИВОСТЬ

docker service scale ip=10 - запуск 10 инстансов сервиса
docker service create --name ip-global --mode global localhost:5000/ip
docker node update node-2 --availability drain - правильный метод отключения ноды

------------------------------------------------------------------------------------------------------------------------
OTHER

docker build -t localhost:5000/api:latest -f apps/api/Dockerfile . 
(localhost - имя registry, куда будем пушить образ, "." - контекст сборки)